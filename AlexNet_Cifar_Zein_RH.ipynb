{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AlexNet_Cifar - Zein RH.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEEpWn2cRorr"
      },
      "source": [
        "# import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Al83ZNzLQXwS"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from keras.models import load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNjQN1Fxz3tC",
        "outputId": "c2c13457-836d-453b-ac9f-37e0fe6ada50"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "drive_path = '/content/drive/MyDrive/UTS_MKTK'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEyxjRemVwdw"
      },
      "source": [
        "# load dataset: CIFAR-10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5of0m0InVsfN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4af56357-b263-438e-c2a5-3be42b32790a"
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = keras.datasets.cifar10.load_data()\n",
        "CLASS_NAMES= ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "170508288/170498071 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoVjA7XyUmjs"
      },
      "source": [
        "filter only airplane, automobile, ship, and truck. each category has 800 data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGy-SrfIjrWY"
      },
      "source": [
        "for i in [0, 1, 8, 9]:\n",
        "  idx = (train_labels == i).reshape(train_images.shape[0])\n",
        "  train_img = train_images[idx][:500]\n",
        "  val_img = train_images[idx][500:750]\n",
        "  test_img = train_images[idx][750:800]\n",
        "  if i == 0:\n",
        "    airplane_img_tr = train_img\n",
        "    airplane_img_val = val_img\n",
        "    airplane_img_te = test_img    \n",
        "  elif i == 1:\n",
        "    automobile_img_tr = train_img\n",
        "    automobile_img_val = val_img\n",
        "    automobile_img_te = test_img\n",
        "  elif i == 8:\n",
        "    ship_img_tr = train_img\n",
        "    ship_img_val = val_img\n",
        "    ship_img_te = test_img\n",
        "  else:\n",
        "    truck_img_tr = train_img\n",
        "    truck_img_val = val_img\n",
        "    truck_img_te = test_img\n",
        "\n",
        "training_image = np.concatenate((airplane_img_tr, automobile_img_tr, ship_img_tr, truck_img_tr), axis=0)\n",
        "validation_image = np.concatenate((airplane_img_val, automobile_img_val, ship_img_val, truck_img_val), axis=0)\n",
        "testing_image = np.concatenate((airplane_img_te, automobile_img_te, ship_img_te, truck_img_te), axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uN5_lTdNiLie"
      },
      "source": [
        "A = []\n",
        "B = []\n",
        "C = []\n",
        "D = []\n",
        "for i in range(500):\n",
        "  A.append([0])\n",
        "  B.append([1])\n",
        "  C.append([2])\n",
        "  D.append([3])\n",
        "\n",
        "A = np.array(A)\n",
        "B = np.array(B)\n",
        "C = np.array(C)\n",
        "D = np.array(D)\n",
        "\n",
        "training_label = np.concatenate((A, B, C, D), axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5CFIIVFkLXD"
      },
      "source": [
        "A = []\n",
        "B = []\n",
        "C = []\n",
        "D = []\n",
        "for i in range(250):\n",
        "  A.append([0])\n",
        "  B.append([1])\n",
        "  C.append([2])\n",
        "  D.append([3])\n",
        "\n",
        "A = np.array(A)\n",
        "B = np.array(B)\n",
        "C = np.array(C)\n",
        "D = np.array(D)\n",
        "\n",
        "validation_label = np.concatenate((A, B, C, D), axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnBV5iEfkMRp"
      },
      "source": [
        "A = []\n",
        "B = []\n",
        "C = []\n",
        "D = []\n",
        "for i in range(50):\n",
        "  A.append([0])\n",
        "  B.append([1])\n",
        "  C.append([2])\n",
        "  D.append([3])\n",
        "\n",
        "A = np.array(A)\n",
        "B = np.array(B)\n",
        "C = np.array(C)\n",
        "D = np.array(D)\n",
        "\n",
        "testing_label = np.concatenate((A, B, C, D), axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6xM1georxh8",
        "outputId": "f7eef5df-973c-4f1b-d4a0-3f784c2a3d34"
      },
      "source": [
        "print(training_image.shape)\n",
        "print(validation_image.shape)\n",
        "print(testing_image.shape)\n",
        "\n",
        "print(training_label.shape)\n",
        "print(validation_label.shape)\n",
        "print(testing_label.shape)\n",
        "\n",
        "class_names = ['airplane', 'automobile', 'ship', 'truck']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2000, 32, 32, 3)\n",
            "(1000, 32, 32, 3)\n",
            "(200, 32, 32, 3)\n",
            "(2000, 1)\n",
            "(1000, 1)\n",
            "(200, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-MNdBWkWN8A"
      },
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices((training_image, training_label))\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((testing_image, testing_label))\n",
        "validation_ds = tf.data.Dataset.from_tensor_slices((validation_image, validation_label))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoCn347wYvRt"
      },
      "source": [
        "# define Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zA1XtdRvYSNm"
      },
      "source": [
        "def process_images(image, label):\n",
        "    image = tf.image.per_image_standardization(image) #strandarisasi\n",
        "    image = tf.image.resize(image, (224,224))         #resize\n",
        "    return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqutXg3QY_uE",
        "outputId": "eea8806b-c88e-49b3-dbf7-4360ee758215"
      },
      "source": [
        "train_ds_size = tf.data.experimental.cardinality(train_ds).numpy()\n",
        "test_ds_size = tf.data.experimental.cardinality(test_ds).numpy()\n",
        "validation_ds_size = tf.data.experimental.cardinality(validation_ds).numpy()\n",
        "print(\"Training data size:\", train_ds_size)\n",
        "print(\"Test data size:\", test_ds_size)\n",
        "print(\"Validation data size:\", validation_ds_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data size: 2000\n",
            "Test data size: 200\n",
            "Validation data size: 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mc3ljaH0eLoC"
      },
      "source": [
        "train_ds = (train_ds\n",
        "                  .map(process_images)\n",
        "                  .shuffle(buffer_size=train_ds_size)\n",
        "                  .batch(batch_size=10, drop_remainder=True))\n",
        "test_ds = (test_ds\n",
        "                  .map(process_images)\n",
        "                  .shuffle(buffer_size=train_ds_size)\n",
        "                  .batch(batch_size=10, drop_remainder=True))\n",
        "validation_ds = (validation_ds\n",
        "                  .map(process_images)\n",
        "                  .shuffle(buffer_size=train_ds_size)\n",
        "                  .batch(batch_size=10, drop_remainder=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wB-8SAZ2j812"
      },
      "source": [
        "# model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kbmhz4pFj5Wa"
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(224,224,3)),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "    keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(4096, activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(4096, activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(4, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fY8wl7mseEC9"
      },
      "source": [
        "root_logdir = os.path.join(os.curdir, \"logs\\\\fit\\\\\")\n",
        "def get_run_logdir():\n",
        "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
        "    return os.path.join(root_logdir, run_id)\n",
        "run_logdir = get_run_logdir()\n",
        "\n",
        "#Defining callbacks to get the best model possible\n",
        "my_calls = [keras.callbacks.EarlyStopping(monitor='val_loss',patience=50),\n",
        "            keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=10, min_lr=1.5e-5),\n",
        "            keras.callbacks.ModelCheckpoint(drive_path + \"/Model1.h5\",verbose=1,save_best_only=True),\n",
        "            keras.callbacks.TensorBoard(run_logdir)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkDGpTDekNTL",
        "outputId": "2d249e19-d326-49b8-b1f5-1c4a0c6eb271"
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.optimizers.Adam(lr=0.001), metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 54, 54, 96)        34944     \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 54, 54, 96)       384       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 26, 26, 96)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 26, 26, 256)       614656    \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 26, 26, 256)      1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 12, 12, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 12, 12, 384)       885120    \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 12, 12, 384)      1536      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 12, 12, 384)       1327488   \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 12, 12, 384)      1536      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 12, 12, 256)       884992    \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 12, 12, 256)      1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 5, 5, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 6400)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4096)              26218496  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 4)                 16388     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 46,768,900\n",
            "Trainable params: 46,766,148\n",
            "Non-trainable params: 2,752\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xYx9ZvDkPwh",
        "outputId": "221cc10b-dab3-4218-8dbe-8d07528a5561"
      },
      "source": [
        "model.fit(train_ds,\n",
        "          epochs=100,\n",
        "          validation_data=validation_ds,\n",
        "          validation_freq=1,\n",
        "          callbacks=my_calls)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 9.0778 - accuracy: 0.3820\n",
            "Epoch 00001: val_loss improved from inf to 1.57699, saving model to /content/drive/MyDrive/UTS_MKTK/Model1.h5\n",
            "200/200 [==============================] - 49s 85ms/step - loss: 9.0778 - accuracy: 0.3820 - val_loss: 1.5770 - val_accuracy: 0.4310 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.6915 - accuracy: 0.4185\n",
            "Epoch 00002: val_loss improved from 1.57699 to 1.18458, saving model to /content/drive/MyDrive/UTS_MKTK/Model1.h5\n",
            "200/200 [==============================] - 18s 87ms/step - loss: 1.6915 - accuracy: 0.4185 - val_loss: 1.1846 - val_accuracy: 0.4580 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.5269 - accuracy: 0.4310\n",
            "Epoch 00003: val_loss improved from 1.18458 to 1.16258, saving model to /content/drive/MyDrive/UTS_MKTK/Model1.h5\n",
            "200/200 [==============================] - 21s 100ms/step - loss: 1.5269 - accuracy: 0.4310 - val_loss: 1.1626 - val_accuracy: 0.5040 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.3548 - accuracy: 0.4560\n",
            "Epoch 00004: val_loss did not improve from 1.16258\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 1.3548 - accuracy: 0.4560 - val_loss: 1.3269 - val_accuracy: 0.4100 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.3496 - accuracy: 0.4510\n",
            "Epoch 00005: val_loss did not improve from 1.16258\n",
            "200/200 [==============================] - 15s 72ms/step - loss: 1.3496 - accuracy: 0.4510 - val_loss: 1.2368 - val_accuracy: 0.4960 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.3461 - accuracy: 0.4495\n",
            "Epoch 00006: val_loss did not improve from 1.16258\n",
            "200/200 [==============================] - 15s 71ms/step - loss: 1.3461 - accuracy: 0.4495 - val_loss: 1.2446 - val_accuracy: 0.4580 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.3532 - accuracy: 0.4625\n",
            "Epoch 00007: val_loss improved from 1.16258 to 1.16145, saving model to /content/drive/MyDrive/UTS_MKTK/Model1.h5\n",
            "200/200 [==============================] - 20s 96ms/step - loss: 1.3532 - accuracy: 0.4625 - val_loss: 1.1615 - val_accuracy: 0.5080 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.3562 - accuracy: 0.4500\n",
            "Epoch 00008: val_loss did not improve from 1.16145\n",
            "200/200 [==============================] - 16s 74ms/step - loss: 1.3562 - accuracy: 0.4500 - val_loss: 1.2514 - val_accuracy: 0.3860 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.2487 - accuracy: 0.4815\n",
            "Epoch 00009: val_loss improved from 1.16145 to 1.15989, saving model to /content/drive/MyDrive/UTS_MKTK/Model1.h5\n",
            "200/200 [==============================] - 20s 96ms/step - loss: 1.2487 - accuracy: 0.4815 - val_loss: 1.1599 - val_accuracy: 0.5030 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.2885 - accuracy: 0.4690\n",
            "Epoch 00010: val_loss did not improve from 1.15989\n",
            "200/200 [==============================] - 15s 72ms/step - loss: 1.2885 - accuracy: 0.4690 - val_loss: 1.2500 - val_accuracy: 0.5190 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.3334 - accuracy: 0.4595\n",
            "Epoch 00011: val_loss did not improve from 1.15989\n",
            "200/200 [==============================] - 15s 71ms/step - loss: 1.3334 - accuracy: 0.4595 - val_loss: 1.2150 - val_accuracy: 0.4060 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.2156 - accuracy: 0.4925\n",
            "Epoch 00012: val_loss improved from 1.15989 to 1.08418, saving model to /content/drive/MyDrive/UTS_MKTK/Model1.h5\n",
            "200/200 [==============================] - 20s 99ms/step - loss: 1.2156 - accuracy: 0.4925 - val_loss: 1.0842 - val_accuracy: 0.5580 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.2253 - accuracy: 0.4965\n",
            "Epoch 00013: val_loss did not improve from 1.08418\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 1.2253 - accuracy: 0.4965 - val_loss: 1.1528 - val_accuracy: 0.4870 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.2512 - accuracy: 0.4930\n",
            "Epoch 00014: val_loss did not improve from 1.08418\n",
            "200/200 [==============================] - 15s 71ms/step - loss: 1.2512 - accuracy: 0.4930 - val_loss: 1.1958 - val_accuracy: 0.4820 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.1811 - accuracy: 0.5025\n",
            "Epoch 00015: val_loss did not improve from 1.08418\n",
            "200/200 [==============================] - 15s 71ms/step - loss: 1.1811 - accuracy: 0.5025 - val_loss: 1.2022 - val_accuracy: 0.5270 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.2043 - accuracy: 0.4950\n",
            "Epoch 00016: val_loss did not improve from 1.08418\n",
            "200/200 [==============================] - 15s 72ms/step - loss: 1.2043 - accuracy: 0.4950 - val_loss: 1.2203 - val_accuracy: 0.4550 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.2234 - accuracy: 0.4870\n",
            "Epoch 00017: val_loss improved from 1.08418 to 1.06318, saving model to /content/drive/MyDrive/UTS_MKTK/Model1.h5\n",
            "200/200 [==============================] - 20s 98ms/step - loss: 1.2234 - accuracy: 0.4870 - val_loss: 1.0632 - val_accuracy: 0.5690 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.1565 - accuracy: 0.5385\n",
            "Epoch 00018: val_loss improved from 1.06318 to 1.05286, saving model to /content/drive/MyDrive/UTS_MKTK/Model1.h5\n",
            "200/200 [==============================] - 18s 86ms/step - loss: 1.1565 - accuracy: 0.5385 - val_loss: 1.0529 - val_accuracy: 0.5570 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.1297 - accuracy: 0.5390\n",
            "Epoch 00019: val_loss improved from 1.05286 to 1.01862, saving model to /content/drive/MyDrive/UTS_MKTK/Model1.h5\n",
            "200/200 [==============================] - 18s 89ms/step - loss: 1.1297 - accuracy: 0.5390 - val_loss: 1.0186 - val_accuracy: 0.5880 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.0745 - accuracy: 0.5515\n",
            "Epoch 00020: val_loss did not improve from 1.01862\n",
            "200/200 [==============================] - 16s 75ms/step - loss: 1.0745 - accuracy: 0.5515 - val_loss: 1.1032 - val_accuracy: 0.5490 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.0922 - accuracy: 0.5580\n",
            "Epoch 00021: val_loss did not improve from 1.01862\n",
            "200/200 [==============================] - 15s 72ms/step - loss: 1.0922 - accuracy: 0.5580 - val_loss: 1.0684 - val_accuracy: 0.5480 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.0710 - accuracy: 0.5630\n",
            "Epoch 00022: val_loss did not improve from 1.01862\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 1.0710 - accuracy: 0.5630 - val_loss: 1.1325 - val_accuracy: 0.5470 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.0084 - accuracy: 0.5960\n",
            "Epoch 00023: val_loss did not improve from 1.01862\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 1.0084 - accuracy: 0.5960 - val_loss: 1.0709 - val_accuracy: 0.5940 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.0247 - accuracy: 0.5925\n",
            "Epoch 00024: val_loss did not improve from 1.01862\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 1.0247 - accuracy: 0.5925 - val_loss: 1.0524 - val_accuracy: 0.5800 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.9326 - accuracy: 0.6285\n",
            "Epoch 00025: val_loss did not improve from 1.01862\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.9326 - accuracy: 0.6285 - val_loss: 1.0788 - val_accuracy: 0.5620 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.9636 - accuracy: 0.6230\n",
            "Epoch 00026: val_loss did not improve from 1.01862\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.9636 - accuracy: 0.6230 - val_loss: 1.1068 - val_accuracy: 0.5800 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.9296 - accuracy: 0.6330\n",
            "Epoch 00027: val_loss improved from 1.01862 to 0.92575, saving model to /content/drive/MyDrive/UTS_MKTK/Model1.h5\n",
            "200/200 [==============================] - 20s 99ms/step - loss: 0.9296 - accuracy: 0.6330 - val_loss: 0.9258 - val_accuracy: 0.6230 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.8868 - accuracy: 0.6660\n",
            "Epoch 00028: val_loss did not improve from 0.92575\n",
            "200/200 [==============================] - 16s 76ms/step - loss: 0.8868 - accuracy: 0.6660 - val_loss: 0.9498 - val_accuracy: 0.6030 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.7783 - accuracy: 0.7225\n",
            "Epoch 00029: val_loss did not improve from 0.92575\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.7783 - accuracy: 0.7225 - val_loss: 0.9269 - val_accuracy: 0.6390 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.7609 - accuracy: 0.7165\n",
            "Epoch 00030: val_loss improved from 0.92575 to 0.91612, saving model to /content/drive/MyDrive/UTS_MKTK/Model1.h5\n",
            "200/200 [==============================] - 20s 99ms/step - loss: 0.7609 - accuracy: 0.7165 - val_loss: 0.9161 - val_accuracy: 0.6510 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.7673 - accuracy: 0.7165\n",
            "Epoch 00031: val_loss did not improve from 0.91612\n",
            "200/200 [==============================] - 16s 77ms/step - loss: 0.7673 - accuracy: 0.7165 - val_loss: 0.9389 - val_accuracy: 0.6390 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.7915 - accuracy: 0.7160\n",
            "Epoch 00032: val_loss did not improve from 0.91612\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.7915 - accuracy: 0.7160 - val_loss: 0.9852 - val_accuracy: 0.5890 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.6390 - accuracy: 0.7555\n",
            "Epoch 00033: val_loss improved from 0.91612 to 0.79935, saving model to /content/drive/MyDrive/UTS_MKTK/Model1.h5\n",
            "200/200 [==============================] - 21s 101ms/step - loss: 0.6390 - accuracy: 0.7555 - val_loss: 0.7993 - val_accuracy: 0.6930 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5876 - accuracy: 0.8010\n",
            "Epoch 00034: val_loss did not improve from 0.79935\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.5876 - accuracy: 0.8010 - val_loss: 1.5061 - val_accuracy: 0.5900 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5758 - accuracy: 0.7930\n",
            "Epoch 00035: val_loss did not improve from 0.79935\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.5758 - accuracy: 0.7930 - val_loss: 0.9413 - val_accuracy: 0.7070 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5381 - accuracy: 0.8145\n",
            "Epoch 00036: val_loss did not improve from 0.79935\n",
            "200/200 [==============================] - 16s 74ms/step - loss: 0.5381 - accuracy: 0.8145 - val_loss: 0.9059 - val_accuracy: 0.6730 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.4720 - accuracy: 0.8405\n",
            "Epoch 00037: val_loss did not improve from 0.79935\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.4720 - accuracy: 0.8405 - val_loss: 1.0190 - val_accuracy: 0.6850 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.4268 - accuracy: 0.8495\n",
            "Epoch 00038: val_loss did not improve from 0.79935\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.4268 - accuracy: 0.8495 - val_loss: 1.0024 - val_accuracy: 0.6860 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.4208 - accuracy: 0.8570\n",
            "Epoch 00039: val_loss did not improve from 0.79935\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.4208 - accuracy: 0.8570 - val_loss: 1.0503 - val_accuracy: 0.7220 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.3646 - accuracy: 0.8735\n",
            "Epoch 00040: val_loss did not improve from 0.79935\n",
            "200/200 [==============================] - 16s 74ms/step - loss: 0.3646 - accuracy: 0.8735 - val_loss: 1.0548 - val_accuracy: 0.7010 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.3633 - accuracy: 0.8695\n",
            "Epoch 00041: val_loss did not improve from 0.79935\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.3633 - accuracy: 0.8695 - val_loss: 1.0577 - val_accuracy: 0.6830 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.3167 - accuracy: 0.8950\n",
            "Epoch 00042: val_loss did not improve from 0.79935\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.3167 - accuracy: 0.8950 - val_loss: 1.3561 - val_accuracy: 0.7160 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.3163 - accuracy: 0.9030\n",
            "Epoch 00043: val_loss did not improve from 0.79935\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.3163 - accuracy: 0.9030 - val_loss: 1.2723 - val_accuracy: 0.6830 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.2020 - accuracy: 0.9375\n",
            "Epoch 00044: val_loss did not improve from 0.79935\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.2020 - accuracy: 0.9375 - val_loss: 0.8632 - val_accuracy: 0.7630 - lr: 1.0000e-04\n",
            "Epoch 45/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.1062 - accuracy: 0.9665\n",
            "Epoch 00045: val_loss did not improve from 0.79935\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.1062 - accuracy: 0.9665 - val_loss: 0.9881 - val_accuracy: 0.7660 - lr: 1.0000e-04\n",
            "Epoch 46/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0767 - accuracy: 0.9715\n",
            "Epoch 00046: val_loss did not improve from 0.79935\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0767 - accuracy: 0.9715 - val_loss: 1.0226 - val_accuracy: 0.7700 - lr: 1.0000e-04\n",
            "Epoch 47/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0547 - accuracy: 0.9805\n",
            "Epoch 00047: val_loss did not improve from 0.79935\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0547 - accuracy: 0.9805 - val_loss: 1.1147 - val_accuracy: 0.7740 - lr: 1.0000e-04\n",
            "Epoch 48/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0582 - accuracy: 0.9835\n",
            "Epoch 00048: val_loss did not improve from 0.79935\n",
            "200/200 [==============================] - 16s 74ms/step - loss: 0.0582 - accuracy: 0.9835 - val_loss: 1.1391 - val_accuracy: 0.7700 - lr: 1.0000e-04\n",
            "Epoch 49/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0506 - accuracy: 0.9810\n",
            "Epoch 00049: val_loss did not improve from 0.79935\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0506 - accuracy: 0.9810 - val_loss: 1.1864 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
            "Epoch 50/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0315 - accuracy: 0.9880\n",
            "Epoch 00050: val_loss did not improve from 0.79935\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0315 - accuracy: 0.9880 - val_loss: 1.2637 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
            "Epoch 51/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0340 - accuracy: 0.9895\n",
            "Epoch 00051: val_loss did not improve from 0.79935\n",
            "200/200 [==============================] - 16s 75ms/step - loss: 0.0340 - accuracy: 0.9895 - val_loss: 1.3945 - val_accuracy: 0.7850 - lr: 1.0000e-04\n",
            "Epoch 52/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0377 - accuracy: 0.9870\n",
            "Epoch 00052: val_loss did not improve from 0.79935\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0377 - accuracy: 0.9870 - val_loss: 1.3373 - val_accuracy: 0.7820 - lr: 1.0000e-04\n",
            "Epoch 53/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0264 - accuracy: 0.9925\n",
            "Epoch 00053: val_loss did not improve from 0.79935\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0264 - accuracy: 0.9925 - val_loss: 1.3619 - val_accuracy: 0.7870 - lr: 1.0000e-04\n",
            "Epoch 54/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0178 - accuracy: 0.9950\n",
            "Epoch 00054: val_loss did not improve from 0.79935\n",
            "200/200 [==============================] - 16s 75ms/step - loss: 0.0178 - accuracy: 0.9950 - val_loss: 1.3585 - val_accuracy: 0.7870 - lr: 1.5000e-05\n",
            "Epoch 55/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 0.9950\n",
            "Epoch 00055: val_loss did not improve from 0.79935\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0168 - accuracy: 0.9950 - val_loss: 1.3670 - val_accuracy: 0.7860 - lr: 1.5000e-05\n",
            "Epoch 56/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0173 - accuracy: 0.9940\n",
            "Epoch 00056: val_loss did not improve from 0.79935\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0173 - accuracy: 0.9940 - val_loss: 1.3751 - val_accuracy: 0.7900 - lr: 1.5000e-05\n",
            "Epoch 57/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0222 - accuracy: 0.9930\n",
            "Epoch 00057: val_loss did not improve from 0.79935\n",
            "200/200 [==============================] - 16s 74ms/step - loss: 0.0222 - accuracy: 0.9930 - val_loss: 1.3805 - val_accuracy: 0.7940 - lr: 1.5000e-05\n",
            "Epoch 58/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0192 - accuracy: 0.9930\n",
            "Epoch 00058: val_loss did not improve from 0.79935\n",
            "200/200 [==============================] - 15s 72ms/step - loss: 0.0192 - accuracy: 0.9930 - val_loss: 1.3992 - val_accuracy: 0.7920 - lr: 1.5000e-05\n",
            "Epoch 59/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0171 - accuracy: 0.9950\n",
            "Epoch 00059: val_loss did not improve from 0.79935\n",
            "200/200 [==============================] - 15s 72ms/step - loss: 0.0171 - accuracy: 0.9950 - val_loss: 1.4157 - val_accuracy: 0.7860 - lr: 1.5000e-05\n",
            "Epoch 60/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0161 - accuracy: 0.9955\n",
            "Epoch 00060: val_loss did not improve from 0.79935\n",
            "200/200 [==============================] - 15s 72ms/step - loss: 0.0161 - accuracy: 0.9955 - val_loss: 1.4294 - val_accuracy: 0.7920 - lr: 1.5000e-05\n",
            "Epoch 61/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 0.9955\n",
            "Epoch 00061: val_loss did not improve from 0.79935\n",
            "200/200 [==============================] - 15s 72ms/step - loss: 0.0168 - accuracy: 0.9955 - val_loss: 1.4224 - val_accuracy: 0.7900 - lr: 1.5000e-05\n",
            "Epoch 62/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 0.9960\n",
            "Epoch 00062: val_loss did not improve from 0.79935\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0114 - accuracy: 0.9960 - val_loss: 1.4546 - val_accuracy: 0.7880 - lr: 1.5000e-05\n",
            "Epoch 63/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0120 - accuracy: 0.9970\n",
            "Epoch 00063: val_loss did not improve from 0.79935\n",
            "200/200 [==============================] - 15s 72ms/step - loss: 0.0120 - accuracy: 0.9970 - val_loss: 1.4594 - val_accuracy: 0.7940 - lr: 1.5000e-05\n",
            "Epoch 64/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.9955\n",
            "Epoch 00064: val_loss did not improve from 0.79935\n",
            "200/200 [==============================] - 15s 72ms/step - loss: 0.0150 - accuracy: 0.9955 - val_loss: 1.4851 - val_accuracy: 0.7950 - lr: 1.5000e-05\n",
            "Epoch 65/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.9985\n",
            "Epoch 00065: val_loss did not improve from 0.79935\n",
            "200/200 [==============================] - 15s 72ms/step - loss: 0.0070 - accuracy: 0.9985 - val_loss: 1.4964 - val_accuracy: 0.7950 - lr: 1.5000e-05\n",
            "Epoch 66/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0139 - accuracy: 0.9970\n",
            "Epoch 00066: val_loss did not improve from 0.79935\n",
            "200/200 [==============================] - 15s 72ms/step - loss: 0.0139 - accuracy: 0.9970 - val_loss: 1.4820 - val_accuracy: 0.7910 - lr: 1.5000e-05\n",
            "Epoch 67/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0154 - accuracy: 0.9945\n",
            "Epoch 00067: val_loss did not improve from 0.79935\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0154 - accuracy: 0.9945 - val_loss: 1.4946 - val_accuracy: 0.7950 - lr: 1.5000e-05\n",
            "Epoch 68/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0119 - accuracy: 0.9965\n",
            "Epoch 00068: val_loss did not improve from 0.79935\n",
            "200/200 [==============================] - 16s 74ms/step - loss: 0.0119 - accuracy: 0.9965 - val_loss: 1.5002 - val_accuracy: 0.7910 - lr: 1.5000e-05\n",
            "Epoch 69/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0165 - accuracy: 0.9945\n",
            "Epoch 00069: val_loss did not improve from 0.79935\n",
            "200/200 [==============================] - 15s 72ms/step - loss: 0.0165 - accuracy: 0.9945 - val_loss: 1.4784 - val_accuracy: 0.7920 - lr: 1.5000e-05\n",
            "Epoch 70/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0142 - accuracy: 0.9955\n",
            "Epoch 00070: val_loss did not improve from 0.79935\n",
            "200/200 [==============================] - 15s 72ms/step - loss: 0.0142 - accuracy: 0.9955 - val_loss: 1.4929 - val_accuracy: 0.7880 - lr: 1.5000e-05\n",
            "Epoch 71/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 0.9965\n",
            "Epoch 00071: val_loss did not improve from 0.79935\n",
            "200/200 [==============================] - 15s 72ms/step - loss: 0.0093 - accuracy: 0.9965 - val_loss: 1.5240 - val_accuracy: 0.7840 - lr: 1.5000e-05\n",
            "Epoch 72/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0130 - accuracy: 0.9960\n",
            "Epoch 00072: val_loss did not improve from 0.79935\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0130 - accuracy: 0.9960 - val_loss: 1.5514 - val_accuracy: 0.7870 - lr: 1.5000e-05\n",
            "Epoch 73/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0077 - accuracy: 0.9980\n",
            "Epoch 00073: val_loss did not improve from 0.79935\n",
            "200/200 [==============================] - 15s 72ms/step - loss: 0.0077 - accuracy: 0.9980 - val_loss: 1.5496 - val_accuracy: 0.7880 - lr: 1.5000e-05\n",
            "Epoch 74/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0134 - accuracy: 0.9965\n",
            "Epoch 00074: val_loss did not improve from 0.79935\n",
            "200/200 [==============================] - 15s 72ms/step - loss: 0.0134 - accuracy: 0.9965 - val_loss: 1.5416 - val_accuracy: 0.7900 - lr: 1.5000e-05\n",
            "Epoch 75/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 0.9970\n",
            "Epoch 00075: val_loss did not improve from 0.79935\n",
            "200/200 [==============================] - 15s 72ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 1.5881 - val_accuracy: 0.7910 - lr: 1.5000e-05\n",
            "Epoch 76/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0160 - accuracy: 0.9935\n",
            "Epoch 00076: val_loss did not improve from 0.79935\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0160 - accuracy: 0.9935 - val_loss: 1.6238 - val_accuracy: 0.7890 - lr: 1.5000e-05\n",
            "Epoch 77/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 0.9970\n",
            "Epoch 00077: val_loss did not improve from 0.79935\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0079 - accuracy: 0.9970 - val_loss: 1.6130 - val_accuracy: 0.7890 - lr: 1.5000e-05\n",
            "Epoch 78/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 0.9950\n",
            "Epoch 00078: val_loss did not improve from 0.79935\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0121 - accuracy: 0.9950 - val_loss: 1.6051 - val_accuracy: 0.7920 - lr: 1.5000e-05\n",
            "Epoch 79/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 0.9980\n",
            "Epoch 00079: val_loss did not improve from 0.79935\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0073 - accuracy: 0.9980 - val_loss: 1.6340 - val_accuracy: 0.7940 - lr: 1.5000e-05\n",
            "Epoch 80/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9970\n",
            "Epoch 00080: val_loss did not improve from 0.79935\n",
            "200/200 [==============================] - 15s 72ms/step - loss: 0.0092 - accuracy: 0.9970 - val_loss: 1.6488 - val_accuracy: 0.7920 - lr: 1.5000e-05\n",
            "Epoch 81/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.9970\n",
            "Epoch 00081: val_loss did not improve from 0.79935\n",
            "200/200 [==============================] - 15s 72ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 1.6267 - val_accuracy: 0.7900 - lr: 1.5000e-05\n",
            "Epoch 82/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 0.9980\n",
            "Epoch 00082: val_loss did not improve from 0.79935\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0082 - accuracy: 0.9980 - val_loss: 1.6420 - val_accuracy: 0.7900 - lr: 1.5000e-05\n",
            "Epoch 83/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9985\n",
            "Epoch 00083: val_loss did not improve from 0.79935\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0058 - accuracy: 0.9985 - val_loss: 1.6405 - val_accuracy: 0.7880 - lr: 1.5000e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8be04c8c10>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NE2DFHJhzgYa"
      },
      "source": [
        "# load model and evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5Xvij7QzjWp"
      },
      "source": [
        "model = load_model(drive_path + \"/Model1.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iGYz4eBzhL8",
        "outputId": "3e60f864-d5f1-4f7d-cb94-87b239693dc2"
      },
      "source": [
        "model.evaluate(test_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 29s 22ms/step - loss: 0.7335 - accuracy: 0.7150\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7334667444229126, 0.7149999737739563]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}